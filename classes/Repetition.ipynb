{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Repetition(Shapefile):\n",
    "    def __init__(self, datasetNumber, inputFolder, outputFolder):\n",
    "        super().__init__(datasetNumber,inputFolder,outputFolder)\n",
    "\n",
    "\n",
    "\n",
    "    def remove_repetitions_from_components_points(self, comments=True):\n",
    "        \n",
    "        removed_counts = {}\n",
    "        for component, gdf in self.components_points_gdf.items():\n",
    "\n",
    "            all_att = gdf.columns.tolist()\n",
    "            all_att.remove(self.idColumunNodes)\n",
    "\n",
    "            ids_before = gdf[self.idColumunNodes].tolist()\n",
    "            #print(ids_before)\n",
    "\n",
    "            '''if self.idColumunNodes in gdf.columns:\n",
    "                gdf.drop(columns=self.idColumunNodes, inplace=True)\n",
    "                if comments:\n",
    "                    print(f\"The id column '{self.idColumunNodes}' is removed from \", component)\n",
    "            if \"id\" in gdf.columns:\n",
    "                gdf.drop(columns=\"id\", inplace=True)\n",
    "                if comments:\n",
    "                    print(f\"The id column  id is removed from \", component)'''\n",
    "\n",
    "            # Get the initial number of rows\n",
    "            initial_count = len(gdf)\n",
    "\n",
    "            # Remove duplicate rows based on all columns and update the dictionary\n",
    "            self.components_points_gdf[component] = gdf.drop_duplicates(all_att)\n",
    "\n",
    "            ids_after = self.components_points_gdf[component][self.idColumunNodes].tolist()\n",
    "            #print(ids_after)\n",
    "\n",
    "            difference_ids= list(set(ids_before)-set(ids_after))\n",
    "            print(f\"repeated ids {difference_ids}\")\n",
    "\n",
    "            # Calculate the number of removed rows\n",
    "            removed_count = initial_count - len(self.components_points_gdf[component])\n",
    "            removed_counts[component] = removed_count\n",
    "\n",
    "            if comments:\n",
    "                print(f\"The component {component} is saved in the folder {self.output_folder}\")\n",
    "            componentPath = \"Data SIG/\" + self.dataset + \"/\"+self.output_folder+\"/\"+component+\".shp\"  # Path to the nodes shapefile\n",
    "            self.components_points_gdf[component].to_file(componentPath, driver='ESRI Shapefile')\n",
    "\n",
    "        if comments:\n",
    "            table = PrettyTable()\n",
    "            table.field_names = [\"Component\", \"Removed Rows\"]\n",
    "            for component, count in removed_counts.items():\n",
    "                table.add_row([component, count])\n",
    "            print(\"Removed Duplicate Rows:\")\n",
    "            print(table)\n",
    "\n",
    "    def remove_repetitions_pipes(self, comments = False):\n",
    "        self.pipesPath = \"Data SIG/\" + self.dataset + \"/\"+self.input_folder+\"/Pipes.shp\"\n",
    "        self.read_shapefile(\"Pipes\")\n",
    "\n",
    "        all_att = self.gdfPipes.columns.tolist()\n",
    "        all_att.remove(self.idColumunPipes)\n",
    "\n",
    "        ids_before =  self.gdfPipes[self.idColumunPipes].tolist()\n",
    "\n",
    "        # Get the initial number of rows\n",
    "        '''if 'id' in self.gdfPipes.columns:\n",
    "            self.gdfPipes.drop(columns='id', inplace=True)\n",
    "            if comments:\n",
    "                    print(f\"The id column id is removed from Pipes\")\n",
    "        if self.idColumunPipes in self.gdfPipes.columns:\n",
    "            self.gdfPipes.drop(columns=self.idColumunPipes, inplace=True)\n",
    "            if comments:\n",
    "                    print(f\"The id column '{self.idColumunNodes}' is removed from Pipes\")'''\n",
    "            \n",
    "        initial_count = len(self.gdfPipes)\n",
    "        \n",
    "        # Remove duplicate rows based on all columns and update the dictionary\n",
    "        self.gdfPipes = self.gdfPipes.drop_duplicates(all_att)\n",
    "\n",
    "        ids_after = self.gdfPipes[self.idColumunPipes].tolist()\n",
    "        #print(ids_after)\n",
    "\n",
    "        difference_ids= list(set(ids_before)-set(ids_after))\n",
    "        print(f\"repeated ids {difference_ids}\")\n",
    "        \n",
    "        # Calculate the number of removed rows\n",
    "        removed_count = initial_count - len(self.gdfPipes)\n",
    "        if comments:\n",
    "            print(f'The number of removed pipes is {removed_count}')\n",
    "            \n",
    "        path_saved = \"Data SIG/\" + self.dataset + \"/\"+self.output_folder+\"/Pipes.shp\"\n",
    "        self.gdfPipes.to_file(path_saved, driver='ESRI Shapefile')\n",
    "\n",
    "        if comments:\n",
    "            print(f'the pipe databse is saved in {path_saved}')\n",
    "    \n",
    "    def remove_repetitions_nodes_based_on_geometry_combined_file(self, comments=True):\n",
    "        self.nodesPath = \"Data SIG/\" + self.dataset + \"/\"+self.input_folder+\"/Nodes.shp\"\n",
    "        self.read_shapefile(\"Nodes\")\n",
    "        initial_count = len(self.gdfNodes)\n",
    "        # Remove duplicate rows based on geometry and update the dictionary\n",
    "        self.gdfNodes =self.gdfNodes.drop_duplicates(subset=['geometry'])\n",
    "\n",
    "        \n",
    "        removed_count = initial_count - len(self.gdfNodes)\n",
    "\n",
    "        if comments:\n",
    "            print(f'The number of removed pipes is {removed_count}')\n",
    "        \n",
    "        self.add_unique_id_attribute(\"Nodes\")\n",
    "            \n",
    "        path_saved = \"Data SIG/\" + self.dataset + \"/\"+self.output_folder+\"/Nodes.shp\"\n",
    "        self.gdfNodes.to_file(path_saved, driver='ESRI Shapefile')\n",
    "\n",
    "        if comments:\n",
    "            print(f'The pipe databse is saved in {path_saved}')\n",
    "\n",
    "    def repeated_pipes_by_position(self, comments=False):\n",
    "        self.nodesPath = \"Data SIG/\" + self.dataset + \"/\"+self.input_folder+\"/Pipes.shp\"\n",
    "        self.read_shapefile(\"Pipes\")\n",
    "        self.add_unique_id_attribute(\"Pipes\")\n",
    "        # Convert geometry to WKT string for comparison\n",
    "        self.gdfPipes['geometry_wkt'] = self.gdfPipes['geometry'].apply(\n",
    "            lambda geom: geom.wkt if geom is not None else None\n",
    "        )\n",
    "        ids_before =  self.gdfPipes[self.idColumunPipes].tolist()\n",
    "\n",
    "        # Group pipes by geometry and count occurrences\n",
    "        grouped = self.gdfPipes.groupby('geometry_wkt').size()\n",
    "\n",
    "        # Filter groups with count > 1\n",
    "        filtered_groups = grouped[grouped > 1]\n",
    "\n",
    "        # Get the geometries of filtered groups\n",
    "        filtered_geometries_wkt = filtered_groups.index\n",
    "\n",
    "        # Create a dictionary to store categories and their corresponding IDs\n",
    "        categories = {}\n",
    "\n",
    "        totalLength = 0\n",
    "\n",
    "        # Iterate through filtered geometries and populate the dictionary\n",
    "        for geometry_wkt in filtered_geometries_wkt:\n",
    "            if geometry_wkt is None:\n",
    "                continue\n",
    "            ids = self.gdfPipes[self.gdfPipes['geometry_wkt'] == geometry_wkt]['id'].tolist()\n",
    "            categories[geometry_wkt] = ids\n",
    "\n",
    "            totalLength = totalLength + len(categories[geometry_wkt])\n",
    "\n",
    "        ids_after = self.gdfPipes[self.idColumunPipes].tolist()\n",
    "        #print(ids_after)\n",
    "\n",
    "        difference_ids= list(set(ids_before)-set(ids_after))\n",
    "        print(f\"repeated ids {difference_ids}\")\n",
    "\n",
    "        # Print the categories and their IDs\n",
    "        print(\"The number of elements that will be removed :\", totalLength - len(categories))\n",
    "\n",
    "        if comments:\n",
    "            for category_wkt, ids in categories.items():\n",
    "                print(f\"Category: {category_wkt} | IDs: {ids}\")\n",
    "\n",
    "        # Drop the temporary column\n",
    "        self.gdfPipes.drop(columns=['geometry_wkt'], inplace=True)\n",
    "\n",
    "    def repeated_nodes_by_position(self, comments = False):\n",
    "        self.nodesPath = \"Data SIG/\" + self.dataset + \"/\"+self.input_folder+\"/Nodes.shp\"\n",
    "        self.read_shapefile(\"Nodes\")\n",
    "        self.add_unique_id_attribute(\"Nodes\")\n",
    "        # Convert geometry to WKT string for comparison\n",
    "        self.gdfNodes['geometry_wkt'] = self.gdfNodes['geometry'].apply(\n",
    "            lambda geom: geom.wkt if geom is not None else None\n",
    "        )\n",
    "\n",
    "        # Group nodes by geometry and count occurrences\n",
    "        grouped = self.gdfNodes.groupby('geometry_wkt').size()\n",
    "\n",
    "        # Filter groups with count > 1\n",
    "        filtered_groups = grouped[grouped > 1]\n",
    "\n",
    "        # Get the geometries of filtered groups\n",
    "        filtered_geometries_wkt = filtered_groups.index\n",
    "\n",
    "        # Create a dictionary to store categories and their corresponding IDs\n",
    "        categories = {}\n",
    "        totalLength = 0\n",
    "\n",
    "        # Iterate through filtered geometries and populate the dictionary\n",
    "        for geometry_wkt in filtered_geometries_wkt:\n",
    "            if geometry_wkt is None:\n",
    "                continue\n",
    "            ids = self.gdfNodes[self.gdfNodes['geometry_wkt'] == geometry_wkt]['id'].tolist()\n",
    "            categories[geometry_wkt] = ids\n",
    "            totalLength = totalLength + len(categories[geometry_wkt])\n",
    "\n",
    "        print(\"The number of elements that will be removed :\", totalLength - len(categories))\n",
    "\n",
    "        # Print the categories and their IDs\n",
    "        if comments:\n",
    "            for category_wkt, ids in categories.items():\n",
    "                print(f\"Category: {category_wkt} | IDs: {ids}\")\n",
    "\n",
    "        # Drop the temporary column\n",
    "        self.gdfNodes.drop(columns=['geometry_wkt'], inplace=True)\n",
    "\n",
    "    def remove_repetitions_pipes_based_on_geometry(self, comments=True):\n",
    "        \n",
    "        self.pipesPath = \"Data SIG/\" + self.dataset + \"/\"+self.input_folder+\"/Pipes.shp\"\n",
    "        self.read_shapefile(\"Pipes\")\n",
    "\n",
    "        ids_before =  self.gdfPipes[self.idColumunPipes].tolist()\n",
    "\n",
    "        initial_count = len(self.gdfPipes)\n",
    "        self.gdfPipes = self.gdfPipes.drop_duplicates(subset=['geometry'])\n",
    "\n",
    "        ids_after = self.gdfPipes[self.idColumunPipes].tolist()\n",
    "        #print(ids_after)\n",
    "\n",
    "        difference_ids= list(set(ids_before)-set(ids_after))\n",
    "        print(f\"repeated ids {difference_ids}\")\n",
    "\n",
    "        numberRemoved = initial_count - len(self.gdfPipes)\n",
    "\n",
    "        if comments:\n",
    "            print(f'The number of removed pipes is {numberRemoved}')\n",
    "\n",
    "        path_saved = \"Data SIG/\" + self.dataset + \"/\"+self.output_folder+\"/Pipes.shp\"\n",
    "        self.gdfPipes.to_file(path_saved, driver='ESRI Shapefile')\n",
    "\n",
    "        if comments:\n",
    "            print(f'The pipe databse is saved in {path_saved}')\n",
    "    \n",
    "    def remove_repetitions_nodes_based_on_geometry_components(self, comments=True):\n",
    "        removed_counts = {}\n",
    "        for component, gdf in self.components_points_gdf.items():\n",
    "            # Get the initial number of rows\n",
    "            initial_count = len(gdf)\n",
    "            ids_before = gdf[self.idColumunNodes].tolist()\n",
    "\n",
    "            # Remove duplicate rows based on geometry and update the dictionary\n",
    "            self.components_points_gdf[component] = gdf.drop_duplicates(subset=['geometry'])\n",
    "\n",
    "            # Calculate the number of removed rows\n",
    "            removed_count = initial_count - len(self.components_points_gdf[component])\n",
    "            removed_counts[component] = removed_count\n",
    "\n",
    "            ids_after = self.components_points_gdf[component][self.idColumunNodes].tolist()\n",
    "            #print(ids_after)\n",
    "\n",
    "            difference_ids= list(set(ids_before)-set(ids_after))\n",
    "            print(f\"repeated ids {difference_ids}\")\n",
    "\n",
    "            if comments:\n",
    "                print(f\"The component {component} is saved in the folder {self.output_folder}\")\n",
    "                componentPath = \"Data SIG/\" + self.dataset + \"/\"+self.output_folder+\"/\"+component+\".shp\"  # Path to the nodes shapefile\n",
    "                self.components_points_gdf[component].to_file(componentPath, driver='ESRI Shapefile')\n",
    "\n",
    "\n",
    "        if comments:\n",
    "            table = PrettyTable()\n",
    "            table.field_names = [\"Component\", \"Removed Rows\"]\n",
    "            for component, count in removed_counts.items():\n",
    "                table.add_row([component, count])\n",
    "            print(\"Removed Duplicate Rows Based on Geometry:\")\n",
    "            print(table)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
