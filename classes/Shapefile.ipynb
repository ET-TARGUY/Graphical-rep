{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9dd3b31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from prettytable import PrettyTable\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import Point, LineString, MultiLineString\n",
    "import math\n",
    "from tabulate import tabulate\n",
    "import networkx as nx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51f695d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Shapefile:\n",
    "    def __init__(self, datasetNumber, inputFolder, outputFolder):\n",
    "        # Initialize the Shapefile class with the given dataset name\n",
    "        \n",
    "        # Call the constructor of the base object class\n",
    "        object.__init__(self)\n",
    "        \n",
    "        self.dataset_number = datasetNumber\n",
    "        self.input_folder = inputFolder\n",
    "        self.output_folder = outputFolder\n",
    "\n",
    "        self.initVariables()\n",
    "\n",
    "\n",
    "        self.min_diameter_m = 0  # Minimum diameter (initialized to 0)\n",
    "\n",
    "\n",
    "    def initVariables(self):\n",
    "        dataset_folders = {\n",
    "            1: \"1402\", 2: \"200213_3M_data\", 3: \"1704/M3M\", 4: \"200211_Veolia_M3M\", 5: \"3M\", 6: \"3MNEW\"\n",
    "        }\n",
    "        self.dataset = dataset_folders.get(self.dataset_number)\n",
    "\n",
    "        self.nodes_path = f\"Data SIG/{self.dataset}/{self.input_folder}/Nodes.shp\"\n",
    "        self.pipes_path = f\"Data SIG/{self.dataset}/{self.input_folder}/Pipes.shp\"\n",
    "\n",
    "        self.points_components = {\n",
    "            \"Manholes\", \"Pumps\", \"Fittings\", \"Structures\", \"TreatmentPlant\", \n",
    "            \"Accessories\", \"Appariel\", \"Deversoir\", \"PosteRefoulement\"\n",
    "        }\n",
    "        self.components_points_gdf = {}\n",
    "        self.attributes_components = {}\n",
    "\n",
    "        self.previousIdsNodes = {1:\"NUMERO\", 2:\"objectid\", 3:\"MSLINK\", 4:\"ID_NODE\", 5:\"idouvrage\" , 6:\"idouvrage\"}\n",
    "        self.previousIdsPipes = {1:\"NUMERO\", 2:\"numero\", 3:\"MSLINK\", 4:\"ID_ARC\", 5:\"idcana\", 6:\"idcana\"}\n",
    "        self.idColumunNodes = self.previousIdsNodes[self.dataset_number]\n",
    "        self.idColumunPipes = self.previousIdsPipes[self.dataset_number]\n",
    "\n",
    "        self.bufferPath = \"Data SIG/Buffer.shp\"\n",
    "\n",
    "        self.pipesPathUpdated = \"Data SIG/\" + self.dataset + \"/PipesWithIds.shp\"  # Path to the pipes shapefile\n",
    "        self.dummyPath = \"Data SIG/\" + self.dataset + \"/Dummy.shp\"  # Path to the dummy shapefile\n",
    "\n",
    "\n",
    "\n",
    "    def find_all_components_points_path(self, comments = False):\n",
    "        self.components_points_paths = []\n",
    "        '''\n",
    "        This function searches for all the shapefiles in the dataset folder that belong to points components.\n",
    "        '''\n",
    "        folder_path = \"Data SIG/\"+self.dataset+\"/\"+self.input_folder\n",
    "        for filename in os.listdir(folder_path):\n",
    "            if filename.endswith(\".shp\") and os.path.splitext(filename)[0] in self.points_components:\n",
    "                self.components_points_paths.append(os.path.join(folder_path, filename))\n",
    "\n",
    "        if comments:\n",
    "            print(\"Shapefiles paths representing nodes components\".center(100,\"*\"))\n",
    "            for component in self.components_points_paths:\n",
    "                print(f'Path : {component}')\n",
    "        return True\n",
    "    \n",
    "\n",
    "    def read_all_components_points_paths(self, comments = False):\n",
    "        if comments:\n",
    "            print(\"Opening databases\".center(100,\"*\"))\n",
    "        for path in self.components_points_paths:\n",
    "            gdf = gpd.read_file(path)\n",
    "            # Extract the file name without the extension and create a new 'source_1' attribute\n",
    "            filename = path.split(\"/\")[-1].split(\".\")[0]\n",
    "            self.components_points_gdf[filename] = gdf\n",
    "            if comments:\n",
    "                print(f'The file {path} is correctly opned')\n",
    "\n",
    "    def get_attributes_components_points(self, comments = False):\n",
    "        '''\n",
    "        This function retrieves attributes for each component and stores them in the attributes_components dictionary.\n",
    "        '''\n",
    "\n",
    "        for component, gdf in self.components_points_gdf.items():\n",
    "            attributes = list(gdf.columns)\n",
    "            '''attributes.append(\"source_1\")\n",
    "            attributes.append(\"id\")'''\n",
    "            self.attributes_components[component] = attributes\n",
    "        if comments:\n",
    "            table = PrettyTable()\n",
    "            table.field_names = [\"Component\", \"Attributes\"]\n",
    "            for component, attributes in self.attributes_components.items():\n",
    "                table.add_row([component, \", \".join(attributes)])\n",
    "            print(table)\n",
    "\n",
    "        return True \n",
    "    \n",
    "    \n",
    "\n",
    "    '''def remove_id_attribute_from_components_points(self, comments = False):\n",
    "        if comments:\n",
    "            print(f'Romoving id attribute from components points'.center(100,\"*\"))\n",
    "        for component, gdf in self.components_points_gdf.items():\n",
    "            if self.idColumunNodes in gdf.columns:\n",
    "                gdf.drop(columns=self.idColumunNodes, inplace=True)\n",
    "                if comments:\n",
    "                    print(f\"The id column '{self.idColumunNodes}' is removed from \", component)\n",
    "            else:\n",
    "                if comments:\n",
    "                    print(f\"The id column '{self.idColumunNodes}' is not found in : \", component)'''\n",
    "        \n",
    "    \n",
    "    def read_shapefile(self, file):\n",
    "        if file == \"Nodes\":\n",
    "            self.gdfNodes = gpd.read_file(self.nodes_path)\n",
    "            print(f'The shapefile {self.nodes_path} is opned')\n",
    "        elif file == \"Pipes\":\n",
    "            self.gdfPipes = gpd.read_file(self.pipes_path)\n",
    "            print(f'The shapefile {self.pipes_path} is opned')\n",
    "        elif file == \"Buffers\":\n",
    "            self.gdfBuffers = gpd.read_file(self.bufferPath)\n",
    "            print(f'The shapefile {self.bufferPath} is opned')\n",
    "        else:\n",
    "            print('The file name must be Nodes, Pipes or buffers')\n",
    "\n",
    "    def print_shapefile_info(self, file):\n",
    "        if file == \"Nodes\":\n",
    "            gdf = self.gdfNodes\n",
    "        elif file == \"Pipes\":\n",
    "            gdf = self.gdfPipes\n",
    "        elif file == \"Buffers\":\n",
    "            gdf = self.gdfBuffers\n",
    "\n",
    "        print(\"Shapefile Information:\")\n",
    "        print(f\"Number of rows: {len(gdf)}\")\n",
    "        print(f\"CRS (Coordinate Reference System): {gdf.crs}\")\n",
    "        \n",
    "        # Print column names and types\n",
    "        print(\"\\nColumns:\")\n",
    "        for column in gdf.columns:\n",
    "            print(f\"{column}: {gdf[column].dtype}\")\n",
    "\n",
    "        # Print the first few rows of the GeoDataFrame\n",
    "        print(\"\\nFirst 5 rows:\")\n",
    "        print(gdf.head())\n",
    "        \n",
    "    def add_unique_id_attribute(self,file, minValue=1 ):\n",
    "        '''\n",
    "        Adds unique IDs to shapefile layers.\n",
    "        '''\n",
    "        if file == \"Nodes\":\n",
    "            if 'id' in self.gdfNodes.columns:\n",
    "                self.gdfNodes.drop(columns=['id'], inplace=True)\n",
    "            self.gdfNodes['id'] = range(minValue, minValue + len(self.gdfNodes))\n",
    "        elif file == \"Pipes\":\n",
    "            if 'id' in self.gdfPipes.columns:\n",
    "                self.gdfPipes.drop(columns=['id'], inplace=True)\n",
    "            self.gdfPipes['id'] = range(minValue, minValue + len(self.gdfPipes))\n",
    "        elif file == \"Buffers\":\n",
    "            if 'id' in self.gdfBuffers.columns:\n",
    "                self.gdfBuffers.drop(columns=['id'], inplace=True)\n",
    "            self.gdfBuffers['id'] = range(minValue, minValue + len(self.gdfBuffers))\n",
    "        else:\n",
    "            print('The file name must be Nodes, Pipes or buffers')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "    def get_node_attributes(self, typeNode, idObject):\n",
    "        attribute_list = self.attributes_components[typeNode]\n",
    "        row_with_desired_id = self.gdfNodes.loc[self.gdfNodes['id'] == idObject]\n",
    "\n",
    "        attributes = {}\n",
    "\n",
    "        if not row_with_desired_id.empty:\n",
    "            specific_row = row_with_desired_id.iloc[0]\n",
    "            for attribute in attribute_list:\n",
    "                if attribute in specific_row:\n",
    "                    attributes[attribute] = specific_row[attribute]\n",
    "\n",
    "        geometry = self.parse_geometry(attributes['geometry'])\n",
    "\n",
    "        properties = {\n",
    "            key: int(value) if isinstance(value, np.int64) else value\n",
    "            for key, value in attributes.items() if key != 'geometry'\n",
    "        }\n",
    "        feature = {\n",
    "            \"type\": \"Feature\",\n",
    "            \"geometry\": geometry,\n",
    "            \"properties\": properties\n",
    "        }\n",
    "        return feature\n",
    "    \n",
    "    def parse_geometry(self, geometry_point):\n",
    "        if geometry_point.geom_type == 'Point':\n",
    "            longitude, latitude = geometry_point.coords[0]\n",
    "            return {\n",
    "                \"type\": \"Point\",\n",
    "                \"coordinates\": [longitude, latitude]\n",
    "            }\n",
    "        return None\n",
    "\n",
    "    def get_pipe_attributes(self, idObject):\n",
    "        row_with_desired_id = self.gdfPipes.loc[self.gdfPipes['id'] == idObject]\n",
    "        attributes = {}\n",
    "        \n",
    "        for attr, value in row_with_desired_id.items():\n",
    "            # Convert np.int64 to int\n",
    "            if isinstance(value.values[0], np.int64):\n",
    "                value = int(value.values[0])\n",
    "            else:\n",
    "                value = value.values[0]\n",
    "            \n",
    "            # Only include attribute if it's not NaN\n",
    "            if not pd.isna(value) and attr != 'geometry':\n",
    "                attributes[attr] = value\n",
    "        \n",
    "        # Extract the first geometry (index 0)\n",
    "        geometry = row_with_desired_id['geometry'].values[0]\n",
    "        \n",
    "        # Convert the geometry to a GeoJSON-like dictionary if needed\n",
    "        coords1 = []\n",
    "        if geometry.geom_type == \"LineString\":\n",
    "            coords1 = list(geometry.coords)\n",
    "        elif geometry.geom_type == \"MultiLineString\":\n",
    "            for line_string in geometry.geoms:\n",
    "                coords1.append(list(line_string.coords))\n",
    "        else:\n",
    "            coords1 = []\n",
    "        geometry_dict = {\n",
    "            \"type\": geometry.geom_type,\n",
    "            \"coordinates\": coords1\n",
    "        }\n",
    "        \n",
    "        return {\n",
    "            \"type\": \"Feature\",\n",
    "            \"geometry\": geometry_dict,\n",
    "            \"properties\": attributes\n",
    "        }\n",
    "\n",
    "    \n",
    "    def describe_shapefiles(self):\n",
    "        print(\"The total number of edges is :\", self.gdfPipes.shape[0])\n",
    "        print(\"The total number of nodes is :\", self.gdfNodes.shape[0])\n",
    "\n",
    "        # Group by the source column and count the elements in each group\n",
    "        counts = self.gdfNodes.groupby(\"source_1\").size()\n",
    "\n",
    "        # Convert the result to a dictionary\n",
    "        self.counts_dict = counts.to_dict()\n",
    "        \n",
    "        table = PrettyTable()\n",
    "        table.field_names = [\"Node Type\", \"Count\"]\n",
    "\n",
    "        for node_type, count in self.counts_dict.items():\n",
    "            table.add_row([node_type, count])\n",
    "        print(table)  \n",
    "\n",
    "    def get_diameter_pipe(self, pipe_id):\n",
    "        pipe_row = self.gdfPipes[self.gdfPipes['id'] == pipe_id]\n",
    "        \n",
    "        if not pipe_row.empty:\n",
    "            diameter_cm = pipe_row['diametre'].iloc[0]\n",
    "            \n",
    "            # Convert to meters if diameter is not null or 0\n",
    "            if diameter_cm is not None and diameter_cm != 0:\n",
    "                return diameter_cm\n",
    "        return None\n",
    "    \n",
    "    def get_min_diameter_pipes(self):\n",
    "        filtered_diameters_cm = self.gdfPipes['diametre'][\n",
    "            (self.gdfPipes['diametre'].notnull()) & (self.gdfPipes['diametre'] != 0)\n",
    "        ]\n",
    "        \n",
    "        if not filtered_diameters_cm.empty:\n",
    "            min_diameter_cm = filtered_diameters_cm.min()\n",
    "            self.min_diameter_m = min_diameter_cm / 1000.0\n",
    "            return self.min_diameter_m\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    \n",
    "\n",
    "    def insert_buffer(self, new_geometry):\n",
    "        '''# Clear existing features from the GeoDataFrame\n",
    "        self.gdfBuffers = gpd.GeoDataFrame(columns=self.gdfBuffers.columns)'''\n",
    "\n",
    "        # Add the new geometry as a feature using pandas.concat\n",
    "        new_row = gpd.GeoDataFrame({'geometry': [new_geometry]})\n",
    "        self.gdfBuffers = pd.concat([self.gdfBuffers, new_row], ignore_index=True)\n",
    "\n",
    "        # Save the GeoDataFrame to a shapefile\n",
    "        self.gdfBuffers.to_file(self.bufferPath, driver='ESRI Shapefile')\n",
    "\n",
    "    '''def convert_dimensions_to_double_and_rename(self):\n",
    "        # Extract numeric values from 'dimensions' column and convert to float\n",
    "        self.gdfPipes['diametre'] = self.gdfPipes['DIMENSIONS'].str.extract('(\\d+)').astype(float)\n",
    "        \n",
    "        # Drop the original 'dimensions' column\n",
    "        self.gdfPipes.drop(columns=['DIMENSIONS'], inplace=True)\n",
    "\n",
    "    def convert_diametre_to_double(self):\n",
    "        self.gdfPipes['diametre'] = self.gdfPipes['diametre'].str.extract('(\\d+)').astype(float)'''\n",
    "\n",
    "    def save_shapefile(self, file):\n",
    "        if file == \"Nodes\":\n",
    "            if os.path.exists(self.nodes_path):\n",
    "                os.remove(self.nodes_path)\n",
    "            self.gdfNodes.to_file(self.nodes_path, driver='ESRI Shapefile')\n",
    "        elif file == \"Pipes\":\n",
    "            if os.path.exists(self.pipesPathUpdated):\n",
    "                os.remove(self.pipesPathUpdated)\n",
    "            self.gdfPipes.to_file(self.pipesPathUpdated, driver='ESRI Shapefile')\n",
    "        elif file == \"Buffers\":\n",
    "            if os.path.exists(self.bufferPath):\n",
    "                os.remove(self.bufferPath)\n",
    "            self.gdfBuffers.to_file(self.bufferPath, driver='ESRI Shapefile')\n",
    "        else:\n",
    "            print('The file name must be Nodes, Pipes or buffers')\n",
    "\n",
    "    def get_connected_components_pipes(self):\n",
    "\n",
    "        # Create an empty graph\n",
    "        self.graphShapeFile = nx.Graph()\n",
    "\n",
    "        # Iterate through each row in the GeoDataFrame\n",
    "        for idx, row in self.gdfPipes.iterrows():\n",
    "            geometry = row.geometry\n",
    "            if isinstance(geometry, LineString):\n",
    "                # Get the start and end points of the pipe as nodes\n",
    "                start_point = geometry.coords[0]\n",
    "                end_point = geometry.coords[-1]\n",
    "\n",
    "                # Add the nodes to the graph\n",
    "                self.graphShapeFile.add_node(start_point)\n",
    "                self.graphShapeFile.add_node(end_point)\n",
    "\n",
    "                # Add an edge between the start and end points to represent the pipe\n",
    "                self.graphShapeFile.add_edge(start_point, end_point)\n",
    "\n",
    "        # Count the number of connected components in the graph\n",
    "        num_connected_components = nx.number_connected_components(self.graphShapeFile)\n",
    "\n",
    "        return num_connected_components"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
